# Credit Scoring Model — FinTech Project

## Ідея проєкту

У цьому проєкті ми створимо просту модель кредитного скорингу — систему, що передбачає, чи клієнт поверне кредит (no default) чи ні (default).
Це класична задача бінарної класифікації, яка використовується у фінтехі для ухвалення рішень про кредитування.

Проєкт має на меті показати end-to-end Data Science pipeline — від підготовки даних до побудови моделі та її інтерактивної візуалізації у Streamlit. 

## Ціль

Передбачити, чи клієнт стане надійним позичальником, використовуючи доступні фінансові характеристики.
Модель повинна допомагати банку або фінтех-компанії ухвалювати більш зважені рішення.

## Дані

### 1. Основний датасет (для старту)

* **Give Me Some Credit (Kaggle)**
  [https://www.kaggle.com/c/GiveMeSomeCredit](https://www.kaggle.com/c/GiveMeSomeCredit)
  Містить дані про кредитну історію клієнтів: дохід, заборгованість, використання кредитів, прострочки тощо.
  Це чистий і відносно простий набір, ідеальний для навчання.

### 2. Реалістичний датасет (на майбутнє)

* **Home Credit Default Risk (Kaggle)**
  [https://www.kaggle.com/c/home-credit-default-risk](https://www.kaggle.com/c/home-credit-default-risk)

  * Більше даних, складніша структура, справжні проблеми фінтех-аналітики (відсутні значення, різні таблиці, категорії).
  * Його можна використати після завершення базової частини проєкту.

## Що будемо робити

1. Ознайомлення з даними — зрозуміти, що означає кожна ознака, і як виглядає цільова змінна.
2. Попередня обробка (preprocessing) — очистити дані, заповнити пропуски, масштабувати числові змінні.
3. Побудова моделі — навчити базові ML-моделі:

   * Logistic Regression (інтерпретована, класика фінтеху)
   * Random Forest або XGBoost (як потужніший алгоритм)
4. Оцінка моделі — перевірити якість передбачень за допомогою метрик:

   * Accuracy, Precision, Recall, ROC-AUC
5. Візуалізація результатів — побудувати простий Streamlit Dashboard із графіками, таблицями та можливістю перевіряти прогноз для одного клієнта.

## План роботи (4 тижні)

### Тиждень 1 — Розвідка та розуміння даних

* Ознайомитись із описом колонок у датасеті.
* Завантажити дані, переглянути розмір, типи змінних, кількість пропусків.
* Побудувати перші графіки:

  * розподіл цільової змінної (SeriousDlqin2yrs),
  * гістрограми доходу, заборгованості, використання кредитів.
* Зробити короткі висновки про структуру та якість даних.

Результат: базовий EDA (Exploratory Data Analysis) — кілька графіків і опис.

### Тиждень 2 — Підготовка даних

* Обробити пропуски (наприклад, замінити середніми або медіаною).
* Масштабувати числові ознаки (StandardScaler або MinMaxScaler).
* Відділити цільову змінну від ознак.
* Розділити дані на train / test (наприклад, 80/20).

Результат: готовий набір даних для навчання моделі.

### Тиждень 3 — Побудова та оцінка моделей

* Навчити Logistic Regression як базову модель.
* Додати Random Forest або XGBoost (опціонально).
* Порівняти результати за метриками:
  accuracy, precision, recall, roc_auc_score.
* Побудувати ROC-криву.

Результат: таблиця з метриками + графік порівняння моделей.

### Тиждень 4 — Візуалізація результатів у Streamlit

* Створити простий застосунок:

  * Виводить метрики моделі.
  * Показує кілька графіків (ROC, важливість ознак, приклад клієнта).
  * Дозволяє ввести нові дані клієнта та побачити прогноз (approve / reject).
* Використати бібліотеки:

  * streamlit, matplotlib або plotly.

Результат: інтерактивна дашборд-демонстрація моделі.

## Технології

* Python
* Pandas, NumPy — для роботи з даними
* Scikit-learn — для побудови моделей
* Matplotlib / Seaborn / Plotly — для візуалізації
* Streamlit — для інтерфейсу

## Структура репозиторію

```
credit_scoring_project/
│
├── data/                     # Сюди зберігати сирі та оброблені дані
│   ├── raw/                  # Сирові дані (Kaggle CSV)
│   └── processed/            # Підготовлені дані після очищення
│
├── notebooks/                # Jupyter ноутбуки по кроках
│   ├── 01_eda.ipynb          # Розвідка та аналіз даних
│   ├── 02_preprocessing.ipynb# Підготовка даних
│   ├── 03_modeling.ipynb     # Побудова моделей
│   └── 04_evaluation.ipynb   # Оцінка результатів
│
├── app/                      # Streamlit-додаток
│   └── streamlit_app.py      # Інтерактивна візуалізація моделі
│
├── src/                      # Скрипти з кодом
│   ├── data_preprocessing.py # Функції для очищення даних
│   ├── modeling.py           # Функції навчання моделі
│   └── visualization.py      # Побудова графіків
│
├── requirements.txt          # Залежності Python
├── README.md                 # Опис проєкту
└── .gitignore                # Файли, які не потрібно відстежувати в git
```

## Як можна розвивати проєкт далі

Після завершення базової версії можна:

* перейти на Home Credit Default Risk або LendingClub dataset,
* додати поглиблений feature engineering,
* дослідити справедливість (fairness) або прибутковість моделі,
* підготувати Model Card (пояснення для бізнесу).

## Очікуваний результат

* Навички підготовки даних.
* Уміння тренувати та оцінювати ML-моделі.
* Проста демонстраційна Streamlit-апка для портфоліо.
